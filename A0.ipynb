{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS431/631 Big Data Infrastructure\n",
    "### Winter 2018 - Assignment 0\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please edit this (text) cell to provide your name and UW student ID number!**\n",
    "* **Name:** Hao Dong\n",
    "* **ID:**20757585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For this assignment, you will be using Python to do some analysis of the text of Shakespeare's plays.    You should already have uploaded the text file (`Shakespeare.txt`) to the hub.   You should also have downloaded the Python tokenizer module, as `simple_tokenize.py`.\n",
    "\n",
    "Let's first try running some simple Python code to make sure that everything is set up properly and ready to go.   The code in the next box will open `Shakespeare.txt`, read the file line by line, and tokenize each line that it reads in.    Try running the code by selecting the box and typing `Shift-Return`, i.e., hit the carriage return key while you are holding the shift key.   It may take a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'end']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this imports the SimpleTokenize function from the simple_tokenize.py file that you uploaded\n",
    "from simple_tokenize import simple_tokenize\n",
    "\n",
    "# Now, let's tokenize Shakespeare's plays\n",
    "with open('Shakespeare.txt') as f:\n",
    "    for line in f:\n",
    "        # tokenize, one line at a time\n",
    "        t = simple_tokenize(line)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1  (2/10 marks):\n",
    "When the code is being executed, the cell number will change to \\*, i.e., you should see `In [*]` in the left margin next to the cell.   After the code has finished running, the cell number will change to `In [1]` (indicating that this is the first code cell to be executed) and the notebook will display the resulting output immediately after cell.   In this case, you shoueld see the output\n",
    "`['the', 'end']`.   In the next cell, briefly explain why the code produced this output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to Question 1:\n",
    "The code opens Shakespeare.txt as f and for every line in the file, it calls the function simple_tokenize().\n",
    "\n",
    "In the function simple_tokenize(), it firstly turns the parameter to lower characters. Then, by using regular, it returns all words as a list defaultly.\n",
    "\n",
    "Then in the 8th line in the code after calling simple_tokenize(), the return list of words is assigned to t.\n",
    "\n",
    "At the last line int the code, it prints the last t, which is the list of lower words in the last line in Shakespeare.txt -- ['the', 'end']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when you close and halt a notebook, any unsaved work in the notebook will be lost.   To save the contents of your notebook, use `Save and Checkpoint` (from the File menu).   \n",
    "\n",
    "---\n",
    "\n",
    "Now it is time for you to write some code.   Let's find the most frequently appearing tokens in Shakespeare's work.\n",
    "\n",
    "#### Question 2 (4/10 marks):\n",
    "In the next box, write Python code to list the 50 most frequently appearing tokens and their frequency, i.e., the number of times that each occurs.   Please use the `simple_tokenize` function, without modification, to tokenize the text, so that everyone is working with the same definition of what a token is.   If you wish, feel free to start with the Python code in the box above - just copy it from there and paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 27378),\n",
       " ('and', 26082),\n",
       " ('i', 20717),\n",
       " ('to', 19661),\n",
       " ('of', 17473),\n",
       " ('a', 14723),\n",
       " ('you', 13630),\n",
       " ('my', 12490),\n",
       " ('in', 10996),\n",
       " ('that', 10915),\n",
       " ('is', 9137),\n",
       " ('not', 8512),\n",
       " ('with', 7778),\n",
       " ('me', 7777),\n",
       " ('it', 7692),\n",
       " ('for', 7578),\n",
       " ('be', 6867),\n",
       " ('his', 6859),\n",
       " ('your', 6657),\n",
       " ('this', 6606),\n",
       " ('but', 6277),\n",
       " ('he', 6260),\n",
       " ('have', 5885),\n",
       " ('as', 5744),\n",
       " ('thou', 5491),\n",
       " ('him', 5205),\n",
       " ('so', 5056),\n",
       " ('will', 4977),\n",
       " ('what', 4469),\n",
       " ('thy', 4034),\n",
       " ('all', 3923),\n",
       " ('her', 3850),\n",
       " ('no', 3797),\n",
       " ('by', 3768),\n",
       " ('do', 3753),\n",
       " ('shall', 3592),\n",
       " ('if', 3500),\n",
       " ('are', 3405),\n",
       " ('we', 3298),\n",
       " ('thee', 3180),\n",
       " ('on', 3062),\n",
       " ('lord', 3062),\n",
       " ('our', 3061),\n",
       " ('king', 2871),\n",
       " ('good', 2834),\n",
       " ('now', 2789),\n",
       " ('sir', 2763),\n",
       " ('from', 2640),\n",
       " ('o', 2621),\n",
       " ('come', 2519)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from simple_tokenize import simple_tokenize\n",
    "\n",
    "with open('Shakespeare.txt') as f:\n",
    "    t = []\n",
    "    tokenfreq = []\n",
    "    for line in f:\n",
    "        t .extend(simple_tokenize(line))        \n",
    "counts = Counter(t)\n",
    "counts.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to test the code that you have written by running it.   When you submit your notebook to us, we will run your code when we mark you assignment.   As a sanity test on you output, our reference implementation finds that the most frequent word is \"the\", which occurs 27378 times.\n",
    "\n",
    "---\n",
    "\n",
    "Once you have found the 50 most frequent tokens, let's move on to something slightly more complicated.\n",
    "\n",
    "#### Question 3 (4/10 marks):\n",
    "\n",
    "Instead of the most frequent tokens appearing in Shakespeare's works, suppose that we want a list of words that appear after the word \"perfect\", on the same line, in Shakespeare's text. \n",
    "(Note: the \"words\" we are interested in for this question are tokens, as returned by simple_tokenize.)\n",
    "\n",
    "For example, *All's Well That Ends Well* includes the line\n",
    ">  Ere I can perfect mine intents, to kneel.\n",
    "\n",
    "so \"mine\" should be part of the output, since it follows \"perfect\" on this line.  To keep the output from getting too long, include only words that appear after \"perfect\" on more than one line.\n",
    "\n",
    "In the next box, write Python code to list words that follow perfect on more than one line.   As a sanity check on your output, our reference implementation finds 5 such words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'honour', 'in', 'love', 'that', 'yellow'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this box, write Python code to find tokens that follow \"perfect\" in Shakespeare.txt \n",
    "from collections import Counter\n",
    "from simple_tokenize import simple_tokenize\n",
    "\n",
    "with open('Shakespeare.txt') as f:\n",
    "    next_word = []\n",
    "    for line in f:\n",
    "        t = simple_tokenize(line)\n",
    "        if('perfect' in t and t.index('perfect') < len(t) - 1):\n",
    "            next_word.append(t[t.index('perfect') + 1])\n",
    "\n",
    "more_next_word = []\n",
    "counts = Counter(next_word)\n",
    "for word in next_word:\n",
    "    if(counts[word] > 1):\n",
    "        more_next_word.append(word)\n",
    "set(more_next_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!   Don't forget to save your work before closing and halting your notebook.      \n",
    "\n",
    "When you are finished and ready to submit your assignment, download your notebook file (.ipynb) from the hub to your machine, and then follow the submission instructions in the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
